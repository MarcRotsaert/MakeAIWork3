{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MNST gradio app </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as grs\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as trans\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='C:/temp/gradio.log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network(nn.Module):\n",
    "    def __init__(self, inpsiz, hidensiz, numclases):\n",
    "         super(neural_network, self).__init__()\n",
    "         self.inputsiz = inpsiz\n",
    "         self.l1 = nn.Linear(inpsiz, hidensiz) \n",
    "         self.relu = nn.ReLU()\n",
    "         self.l2 = nn.Linear(hidensiz, numclases) \n",
    "    def forward(self, y):\n",
    "         outp = self.l1(y)\n",
    "         outp = self.relu(outp)\n",
    "         outp = self.l2(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.chdir(r'C:\\temp\\maiw_project3\\aws_sagemaker')\n",
    "modl = torch.load('mnst_mod_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method eval in module torch.nn.modules.module:\n",
      "\n",
      "eval() -> ~T method of __main__.neural_network instance\n",
      "    Sets the module in evaluation mode.\n",
      "    \n",
      "    This has any effect only on certain modules. See documentations of\n",
      "    particular modules for details of their behaviors in training/evaluation\n",
      "    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "    etc.\n",
      "    \n",
      "    This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      "    \n",
      "    See :ref:`locally-disable-grad-doc` for a comparison between\n",
      "    `.eval()` and several similar mechanisms that may be confused with it.\n",
      "    \n",
      "    Returns:\n",
      "        Module: self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(modl.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=5,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(5, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, y):\n",
    "        y = self.conv(y)\n",
    "        y = self.conv1(y)\n",
    "        y = y.view(y.size(0), -1)       \n",
    "        outp = self.out(y)\n",
    "        return outp, y  \n",
    "Cnn = cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 784])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m imgs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(imgs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 21\u001b[0m xx\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "inpsiz = 784 \n",
    "hidensiz = 500 \n",
    "numclases = 10\n",
    "numepchs = 8\n",
    "bachsiz = 100\n",
    "l_r = 0.001 #learning Rate\n",
    "\n",
    "testds = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=False, \n",
    "                                           transform=trans.ToTensor()) \n",
    "\n",
    "testldr = torch.utils.data.DataLoader(dataset=testds, \n",
    "                                           batch_size=bachsiz, \n",
    "    \n",
    "    \n",
    "                                           shuffle=False)\n",
    "for x, (imgs, lbls) in enumerate(testldr): \n",
    "    print(imgs.shape)\n",
    "    imgs = imgs.reshape(-1, 28*28)\n",
    "    print(imgs.shape)\n",
    "    xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelpred(img_arr):\n",
    "    print('yes')\n",
    "    with torch.no_grad():\n",
    "\n",
    "        modl.eval()\n",
    "        #out_data = modl(data)\n",
    "        #print((img_arr.dtype)))\n",
    "        try:\n",
    "            print(img_arr)\n",
    "            testoutp= torch.from_numpy(img_arr)\n",
    "            result=modl(testoutp)\n",
    "            print(result)\n",
    "            #print(testoutp)\n",
    "            #testoutp = Cnn(testoutp)\n",
    "            #print(testoutp.shape)\n",
    "            #testoutp, lstlayr = Cnn(img_arr)\n",
    "            #torchvision.transforms.ToTensor()\n",
    "            #temp = torchvision.transforms.ToTensor(img_arr,(28,28,3))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            xx\n",
    "        predicy = torch.max(testoutp, 1)[1].data.squeeze()\n",
    "        print(predicy)\n",
    "        #xx\n",
    "        print(testoutp.shape)\n",
    "        print(predicy.shape)\n",
    "\n",
    "    return predicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTEMP\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mMNIST_2.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39m#print(img)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#print(np.asarray(img).reshape(-1, 28*28).shape)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#print(np.asarray(img).shape)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#print(np.asarray(img).reshape(-1, 28*28))\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pred \u001b[39m=\u001b[39m modelpred(np\u001b[39m.\u001b[39;49masarray(img,dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m28\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m28\u001b[39;49m))\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(pred)\n\u001b[0;32m      8\u001b[0m \u001b[39m#pred = modelpred(np.asarray(img,dtype=np.float32))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#print(pred)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[174], line 22\u001b[0m, in \u001b[0;36mmodelpred\u001b[1;34m(img_arr)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(e)\n\u001b[0;32m     21\u001b[0m     xx\n\u001b[1;32m---> 22\u001b[0m predicy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(testoutp, \u001b[39m1\u001b[39;49m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(predicy)\n\u001b[0;32m     24\u001b[0m \u001b[39m#xx\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "img = PIL.Image.open(r'C:\\TEMP\\MNIST_2.png')\n",
    "#print(img)\n",
    "#print(np.asarray(img).reshape(-1, 28*28).shape)\n",
    "#print(np.asarray(img).shape)\n",
    "#print(np.asarray(img).reshape(-1, 28*28))\n",
    "pred = modelpred(np.asarray(img,dtype=np.float32).reshape(-1, 28*28))\n",
    "print(pred)\n",
    "#pred = modelpred(np.asarray(img,dtype=np.float32))\n",
    "#print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'inputsiz',\n",
       " 'ipu',\n",
       " 'l1',\n",
       " 'l2',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(modl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Running on local URL:  http://127.0.0.1:7891\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7891/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "torch.return_types.max(\n",
      "values=tensor([[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]], dtype=torch.uint8),\n",
      "indices=tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 9,  9,  9],\n",
      "        [ 6,  6,  6],\n",
      "        [ 6,  6,  6],\n",
      "        [ 5,  5,  5],\n",
      "        [ 5,  5,  5],\n",
      "        [ 4,  4,  4],\n",
      "        [ 4,  4,  4],\n",
      "        [20, 20, 20],\n",
      "        [20, 20, 20],\n",
      "        [20, 20, 20],\n",
      "        [19, 19, 19],\n",
      "        [16, 16, 16],\n",
      "        [15, 15, 15],\n",
      "        [12, 12, 12],\n",
      "        [ 9,  9,  9],\n",
      "        [ 5,  5,  5],\n",
      "        [ 3,  3,  3],\n",
      "        [ 3,  3,  3],\n",
      "        [ 4,  4,  4],\n",
      "        [12, 12, 12],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\gradio\\routes.py\", line 292, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\gradio\\blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\gradio\\blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\temp\\gradio_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\marcr\\AppData\\Local\\Temp\\ipykernel_6156\\1101911105.py\", line 15, in modelpred\n",
      "    xx\n",
      "NameError: name 'xx' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def start_gradio():\n",
    "    print('1')\n",
    "    demo = gr.Interface(modelpred, gr.Image(shape=(28, 28)), \"image\")\n",
    "    demo.launch()\n",
    "    return demo\n",
    "demo = start_gradio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(outp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('gradio_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0893075f87b72598f4798b65c5e70d4a719719245bc69132ea65a1c3d937457d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
