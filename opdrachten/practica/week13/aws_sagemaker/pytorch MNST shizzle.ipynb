{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets as dts\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader #let op dubbele hoofdletter\n",
    "from torch.optim import Adam\n",
    "#from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doet cuda het?\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindt = dts.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                             \n",
    "    transform = transforms.ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "testdt = dts.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms instellen (hier zou je de pipeline aanmaken stel dat je dat wil, vind het zelf onhandig en onvoorspelbaar)\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((350,350)),\n",
    "    transforms.ToTensor(),#tensortjes maken zodat torch er mee om kan gaan (zet ook pixel waarden tussen 0 en 1)\n",
    "    transforms.Normalizealize([0.5,0.5,0.5],\n",
    "                         [0.5,0.5,0.5]).cuda()\n",
    "])#deze termen zorgen voor transformatie naar -1 , 1 dit zou beter moeten zijn voor het trainen, ik weet niet waarom\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klassen/labels halen\n",
    "root = Path('data')\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MNIST']\n"
     ]
    }
   ],
   "source": [
    "# gelukt?\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model bouwen \n",
    "# input shape wordt : (32,3,350,350) (batchsize, rgb, dimensions)\n",
    "# batch normalization komt er op neer dat je verspreiding van de range van data steeds weer inkrimpt om het rekenen binnen perken te houden https://arxiv.org/abs/1502.03167\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=4):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=128,kernel_size=3,stride=1,padding='valid')\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,stride=1,padding='valid')\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='valid')\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,stride=1,padding='valid')\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding='valid')\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=2592, out_features = 256,device=device)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features = num_classes,device=device)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.pool3(output)\n",
    "        \n",
    "        output = self.conv4(output)\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.pool4(output)\n",
    "        \n",
    "        output = self.conv5(output)\n",
    "        output = self.bn5(output)\n",
    "        output = self.relu5(output)\n",
    "        output = self.pool5(output)\n",
    "        \n",
    "        # output = output.view(-1,32,9,9)\n",
    "        \n",
    "        output = self.flat(output)\n",
    "        output = self.dropout1(self.fc1(output))\n",
    "        output = self.dropout2(self.fc2(output))\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        # als het goed is komt hier een matrix uit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model op de hardware laden\n",
    "model = ConvNet(num_classes=4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimaaaizer en loss function\n",
    "optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken hoeveel bestanden we hebben voor train en test (alle bestanden)\n",
    "train_count = len(glob.glob(train_path+'/**/*.*'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_count, test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x.device, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainen en opslaan\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "    # zorgen dat de bestanden via de gpu gaan als die beschikbaar is\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "# zorgt dat de optimizer niet verward raakt door mixen van resultaat per batch        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.cpu().data*images.size(0)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "    \n",
    "        train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "    \n",
    "    #test set evalueren\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy = 0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data,1)\n",
    "        test_accuracy += int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(int(train_loss))+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "\n",
    "    # model opslaan als beste is van getraint        \n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_accuracy)\n",
    "# print(model.get_parameters())\n",
    "# print(model)\n",
    "# list(map(lambda x: x.device, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoogst behaald: 0.7333333333333333 - standaard dataset\n",
    "#  - gelijk aantal per klasse, flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e654902f1877883cfc0f8194d1615c44937abe63f3bb0e0105192e55863f0170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
